{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 140. Word Break II"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Topic Alignment\n",
        "- Memoized DFS supports NLP tasks like splitting phrases into dictionary tokens while reusing overlapping sub-solutions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Metadata\n",
        "- Source: https://leetcode.com/problems/word-break-ii/\n",
        "- Tags: DFS, Memoization, String\n",
        "- Difficulty: Hard\n",
        "- Priority: High"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Problem Statement\n",
        "Given a string s and a dictionary of strings wordDict, add spaces in s to construct sentences where each word is in wordDict. Return all such sentences in any order."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Progressive Hints\n",
        "- Hint 1: Use DP or memoization to avoid recomputing suffix decompositions.\n",
        "- Hint 2: DFS(start) can return all sentences for substring s[start:].\n",
        "- Hint 3: Prune using the maximum dictionary word length and feasibility DP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Solution Overview\n",
        "Perform a feasibility DP to ensure s is breakable. Then memoize dfs(start) that returns a list of sentences for suffix starting at index start. At each step, iterate end positions up to maxWord length; when substring is a dictionary word and the remaining suffix is breakable, combine with recursive results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detailed Explanation\n",
        "1. Convert wordDict to a set for O(1) lookup and compute max word length.\n",
        "2. Build dp[i] meaning suffix s[i:] is breakable. Iterate backward to fill dp.\n",
        "3. If dp[0] is False, return [].\n",
        "4. Define dfs(start) with lru_cache. Base case start == n returns [\"\"].\n",
        "5. For each end in [start+1, start+maxLen], if word in dictionary and dp[end], append combinations word + (space + suffix if suffix else \"\").\n",
        "6. Memoization ensures each start position is processed once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complexity Trade-off Table\n",
        "| Approach | Time | Space | Notes |\n",
        "| --- | --- | --- | --- |\n",
        "| DFS + memoization | O(n^2 + output) | O(n * avg_sentences) | Combines DP pruning with cached recursion |\n",
        "| Pure DFS without memo | Exponential | Exponential | Repeatedly recomputes suffix decompositions |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from functools import lru_cache\n",
        "from typing import List\n\n",
        "class Solution:\n",
        "    def wordBreak(self, s: str, wordDict: List[str]) -> List[str]:\n",
        "        word_set = set(wordDict)\n",
        "        if not word_set:\n",
        "            return []\n",
        "        max_len = max(len(w) for w in word_set)\n",
        "        n = len(s)\n",
        "        dp = [False] * (n + 1)\n",
        "        dp[n] = True\n",
        "        for i in range(n - 1, -1, -1):\n",
        "            for j in range(i + 1, min(n, i + max_len) + 1):\n",
        "                if s[i:j] in word_set and dp[j]:\n",
        "                    dp[i] = True\n",
        "                    break\n",
        "        if not dp[0]:\n",
        "            return []\n",
        "        @lru_cache(None)\n",
        "        def dfs(start: int) -> List[str]:\n",
        "            if start == n:\n",
        "                return [\"\"]\n",
        "            sentences: List[str] = []\n",
        "            for end in range(start + 1, min(n, start + max_len) + 1):\n",
        "                word = s[start:end]\n",
        "                if word not in word_set or not dp[end]:\n",
        "                    continue\n",
        "                for suffix in dfs(end):\n",
        "                    sentences.append(word if not suffix else word + \" \" + suffix)\n",
        "            return sentences\n",
        "        return dfs(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "tags": [
          "validation"
        ]
      },
      "outputs": [],
      "source": [
        "tests = [\n",
        "    (\"catsanddog\", [\"cat\",\"cats\",\"and\",\"sand\",\"dog\"], {\"cats and dog\", \"cat sand dog\"}),\n",
        "    (\"pineapplepenapple\", [\"apple\",\"pen\",\"applepen\",\"pine\",\"pineapple\"], {\n",
        "        \"pine apple pen apple\",\n",
        "        \"pineapple pen apple\",\n",
        "        \"pine applepen apple\"\n",
        "    }),\n    (\"catsandog\", [\"cats\",\"dog\",\"sand\",\"and\",\"cat\"], set())\n",
        "]\n",
        "solver = Solution()\n",
        "for s, word_dict, expected in tests:\n",
        "    actual = set(solver.wordBreak(s, word_dict))\n",
        "    assert actual == expected\n",
        "print('All tests passed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Complexity Analysis\n",
        "- Time: O(n^2) for feasibility DP plus cost proportional to number of returned sentences.\n",
        "- Space: O(n^2) in worst case for memoized results; recursion depth O(n)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Edge Cases & Pitfalls\n",
        "- Without dp pruning, DFS may TLE on large impossible strings.\n",
        "- Ensure empty suffix returns [\"\"] so concatenation works cleanly.\n",
        "- Limit substring exploration using max word length."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Follow-up Variants\n",
        "- Count sentences instead of returning them (modulo arithmetic).\n",
        "- Return only lexicographically smallest or first K sentences.\n",
        "- Support wildcard dictionary entries using Trie + DFS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Takeaways\n",
        "- Combining DP feasibility with memoized DFS keeps enumerations tractable.\n",
        "- Memo cache keyed by start index avoids exponential duplication.\n",
        "- Pruning using max word length reduces branching significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Similar Problems\n",
        "| Problem ID | Problem Title | Technique |\n",
        "| --- | --- | --- |\n",
        "| LC 139 | Word Break | DP feasibility only |\n",
        "| LC 472 | Concatenated Words | DFS + memo to reuse substrings |\n",
        "| LC 301 | Remove Invalid Parentheses | DFS with pruning to enumerate valid strings |"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}